import os
from dotenv import load_dotenv
from openai import AzureOpenAI
import streamlit as st
from openai_common import create_chat_model
from langchain_core.messages.chat import ChatMessage
import graph as gh
from langchain_core.messages import HumanMessage

st.title("ğŸ¤– ì—…ë¬´ ì •ë¦¬ Agent")

# Initialize chat history
if "messages" not in st.session_state:
    st.session_state["messages"] = []

if "graph" not in st.session_state:
    st.session_state["graph"] = gh.create_graph()

if "llm" not in st.session_state:
    st.session_state["llm"] = create_chat_model("openai")

if "config" not in st.session_state:
    st.session_state["config"] = {"configurable": {"thread_id": "1"}}


# ìƒˆë¡œìš´ ë©”ì‹œì§€ë¥¼ ì¶”ê°€
def add_message(role, message):
    st.session_state["messages"].append(ChatMessage(role=role, content=message))


# ë©”ì„¸ì§€ ì¶œë ¥
def print_messages():
    for chat_message in st.session_state["messages"]:
        if chat_message["role"] == "user":
            st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»").markdown(chat_message["content"])
        elif chat_message["role"] == "assistant":
            st.chat_message("assistant", avatar="ğŸ¤–").markdown(chat_message["content"])


# ì‚¬ì´ë“œë°” ìƒì„±
with st.sidebar:
    st.title("ğŸ“Š ì›Œí¬í”Œë¡œìš° ëŒ€ì‹œë³´ë“œ")

    # ê·¸ë˜í”„ ì„¹ì…˜
    st.subheader("ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„")
    if "graph" in st.session_state:
        st.image(
            st.session_state["graph"].get_graph().draw_mermaid_png(),
            caption="í˜„ì¬ ì›Œí¬í”Œë¡œìš° êµ¬ì¡°",
            use_container_width=True,
        )

    # êµ¬ë¶„ì„ 
    st.divider()

    # ë„ì›€ë§ ì„¹ì…˜
    with st.expander("â„¹ï¸ ë„ì›€ë§"):
        st.info(
            """
        - ê·¸ë˜í”„ëŠ” í˜„ì¬ ì›Œí¬í”Œë¡œìš°ì˜ êµ¬ì¡°ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤
        """
        )


print_messages()

# Handle user input
if user_input := st.chat_input("ë©”ì„¸ì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”"):
    graph = st.session_state["graph"]

    # ì‚¬ìš©ì ì…ë ¥
    st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»").markdown(user_input)
    st.session_state.messages.append({"role": "user", "content": user_input})

    input = {
        "user_input": user_input,
        "messages": [HumanMessage(content=user_input)],
    }

    github = False

    if len(st.session_state["messages"]) > 1:
        previous_message = st.session_state["messages"][-2]["content"]
        if (
            previous_message
            == "ê¹ƒí—ˆë¸Œ ì‚¬ìš©ì IDì™€ í† í°ì„ ì…ë ¥í•´ì£¼ì„¸ìš”. ex)username, ghp_123..."
        ):
            github = True

    # process í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒíƒœ ë³€í™”ë¥¼ ìŠ¤íŠ¸ë¦¬ë°
    for step in gh.process(input, graph, st.session_state["config"], github):
        # messagesì˜ ë§ˆì§€ë§‰ ë©”ì‹œì§€ë¥¼ í‘œì‹œ
        last_message = step["messages"][-1]
        if last_message.type == "ai":
            st.chat_message("assistant", avatar="ğŸ¤–").markdown(last_message.content)
            st.session_state.messages.append(
                {"role": "assistant", "content": last_message.content}
            )
